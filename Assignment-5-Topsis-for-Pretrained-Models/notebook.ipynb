{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720965eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\SEM-6\\UCS654\\Lecture\\Assignment-5-Topsis-for-Pretrained-Models\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c483c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"sentence-transformers/stsb\", split=\"test\")\n",
    "\n",
    "sentences1 = dataset[\"sentence1\"]\n",
    "sentences2 = dataset[\"sentence2\"]\n",
    "labels = dataset[\"score\"]\n",
    "\n",
    "models = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/paraphrase-MiniLM-L12-v2\",\n",
    "    \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
    "    \"sentence-transformers/distilbert-base-nli-stsb-mean-tokens\",\n",
    "    \"sentence-transformers/bert-base-nli-mean-tokens\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd729a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, s1, s2, labels, sample_size=500):\n",
    "    model = SentenceTransformer(model_name, device=\"cpu\")\n",
    "\n",
    "    s1 = s1[:sample_size]\n",
    "    s2 = s2[:sample_size]\n",
    "    labels = labels[:sample_size]\n",
    "\n",
    "    start = time.time()\n",
    "    emb1 = model.encode(s1, convert_to_numpy=True, show_progress_bar=False)\n",
    "    emb2 = model.encode(s2, convert_to_numpy=True, show_progress_bar=False)\n",
    "    end = time.time()\n",
    "\n",
    "    cosine_sim = np.sum(emb1 * emb2, axis=1) / (\n",
    "        np.linalg.norm(emb1, axis=1) * np.linalg.norm(emb2, axis=1)\n",
    "    )\n",
    "\n",
    "    spearman, _ = spearmanr(cosine_sim, labels)\n",
    "    avg_time_ms = ((end - start) / sample_size) * 1000\n",
    "\n",
    "    return spearman, avg_time_ms, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84caecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import scan_cache_dir\n",
    "\n",
    "def get_model_size_mb(repo_id):\n",
    "    cache_info = scan_cache_dir()\n",
    "    for repo in cache_info.repos:\n",
    "        if repo.repo_id == repo_id:\n",
    "            return repo.size_on_disk / (1024 * 1024)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fc88326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 313.84it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\SEM-6\\UCS654\\Lecture\\Assignment-5-Topsis-for-Pretrained-Models\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kshitiz\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 340.13it/s, Materializing param=pooler.dense.weight]                        \n",
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: sentence-transformers/paraphrase-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\SEM-6\\UCS654\\Lecture\\Assignment-5-Topsis-for-Pretrained-Models\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kshitiz\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|██████████| 199/199 [00:01<00:00, 182.60it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: sentence-transformers/paraphrase-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\SEM-6\\UCS654\\Lecture\\Assignment-5-Topsis-for-Pretrained-Models\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kshitiz\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 310.82it/s, Materializing param=pooler.dense.weight]                        \n",
      "MPNetModel LOAD REPORT from: sentence-transformers/paraphrase-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: sentence-transformers/distilbert-base-nli-stsb-mean-tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\SEM-6\\UCS654\\Lecture\\Assignment-5-Topsis-for-Pretrained-Models\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kshitiz\\.cache\\huggingface\\hub\\models--sentence-transformers--distilbert-base-nli-stsb-mean-tokens. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|██████████| 100/100 [00:00<00:00, 243.36it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: sentence-transformers/bert-base-nli-mean-tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\SEM-6\\UCS654\\Lecture\\Assignment-5-Topsis-for-Pretrained-Models\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kshitiz\\.cache\\huggingface\\hub\\models--sentence-transformers--bert-base-nli-mean-tokens. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 280.54it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: sentence-transformers/bert-base-nli-mean-tokens\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Model  Accuracy    Time_ms     Size_MB\n",
      "0                      all-MiniLM-L6-v2  0.927632   6.343399   87.335937\n",
      "1                     all-mpnet-base-v2  0.930934  49.850491  418.360636\n",
      "2              paraphrase-MiniLM-L12-v2  0.917021  11.850999  127.953589\n",
      "3              paraphrase-mpnet-base-v2  0.935278  40.254031  418.354918\n",
      "4  distilbert-base-nli-stsb-mean-tokens  0.915163  22.171097  253.835472\n",
      "5             bert-base-nli-mean-tokens  0.879270  42.581038  418.337442\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_name in models:\n",
    "    print(f\"Evaluating: {model_name}\")\n",
    "\n",
    "    accuracy, time_ms, _ = evaluate_model(\n",
    "        model_name,\n",
    "        sentences1,\n",
    "        sentences2,\n",
    "        labels\n",
    "    )\n",
    "\n",
    "    size_mb = get_model_size_mb(model_name)\n",
    "\n",
    "    results.append([\n",
    "        model_name.split(\"/\")[-1],\n",
    "        accuracy,\n",
    "        time_ms,\n",
    "        size_mb\n",
    "    ])\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"Model\", \"Accuracy\", \"Time_ms\", \"Size_MB\"]\n",
    ")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04fa2455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOPSIS Ranking:\n",
      "\n",
      "                                  Model  Accuracy    Time_ms     Size_MB  \\\n",
      "0                      all-MiniLM-L6-v2  0.927632   6.343399   87.335937   \n",
      "2              paraphrase-MiniLM-L12-v2  0.917021  11.850999  127.953589   \n",
      "4  distilbert-base-nli-stsb-mean-tokens  0.915163  22.171097  253.835472   \n",
      "3              paraphrase-mpnet-base-v2  0.935278  40.254031  418.354918   \n",
      "5             bert-base-nli-mean-tokens  0.879270  42.581038  418.337442   \n",
      "1                     all-mpnet-base-v2  0.930934  49.850491  418.360636   \n",
      "\n",
      "   TOPSIS_Score  Rank  \n",
      "0      0.990740   1.0  \n",
      "2      0.872677   2.0  \n",
      "4      0.604788   3.0  \n",
      "3      0.199145   4.0  \n",
      "5      0.144654   5.0  \n",
      "1      0.059499   6.0  \n"
     ]
    }
   ],
   "source": [
    "# Decision Matrix\n",
    "decision_matrix = df[[\"Accuracy\", \"Time_ms\", \"Size_MB\"]].values\n",
    "\n",
    "# Weights (sum = 1)\n",
    "weights = np.array([0.50, 0.30, 0.20])\n",
    "\n",
    "# Benefit (+1) / Cost (-1)\n",
    "criteria_type = np.array([1, -1, -1])\n",
    "\n",
    "# Normalize\n",
    "norm_matrix = decision_matrix / np.sqrt((decision_matrix**2).sum(axis=0))\n",
    "\n",
    "# Weighted normalization\n",
    "weighted_matrix = norm_matrix * weights\n",
    "\n",
    "# Ideal best and worst\n",
    "ideal_best = np.where(\n",
    "    criteria_type == 1, weighted_matrix.max(axis=0), weighted_matrix.min(axis=0)\n",
    ")\n",
    "\n",
    "ideal_worst = np.where(\n",
    "    criteria_type == 1, weighted_matrix.min(axis=0), weighted_matrix.max(axis=0)\n",
    ")\n",
    "\n",
    "# Distances\n",
    "dist_best = np.sqrt(((weighted_matrix - ideal_best) ** 2).sum(axis=1))\n",
    "dist_worst = np.sqrt(((weighted_matrix - ideal_worst) ** 2).sum(axis=1))\n",
    "\n",
    "# TOPSIS score\n",
    "df[\"TOPSIS_Score\"] = dist_worst / (dist_best + dist_worst)\n",
    "\n",
    "# Rank\n",
    "df[\"Rank\"] = df[\"TOPSIS_Score\"].rank(ascending=False)\n",
    "df = df.sort_values(\"Rank\")\n",
    "\n",
    "print(\"\\nTOPSIS Ranking:\\n\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
